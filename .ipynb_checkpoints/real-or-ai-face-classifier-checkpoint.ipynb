{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204562f5-feeb-4fee-84ab-414e718d32e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "class AIImageClassifier:\n",
    "    def __init__(self, img_height=224, img_width=224, channels=3):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.channels = channels\n",
    "        self.model = self.build_model()\n",
    "        self.class_names = None\n",
    "\n",
    "    def build_model(self):\n",
    "        base_model = ResNet50V2(\n",
    "            weights='imagenet', \n",
    "            include_top=False, \n",
    "            input_shape=(self.img_height, self.img_width, self.channels)\n",
    "        )\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "            loss='categorical_crossentropy', \n",
    "            metrics=['accuracy', \n",
    "                     tf.keras.metrics.Precision(), \n",
    "                     tf.keras.metrics.Recall()]\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def prepare_data(self, data_dir):\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            validation_split=0.2,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True\n",
    "        )\n",
    "        \n",
    "        train_generator = datagen.flow_from_directory(\n",
    "            data_dir,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical',\n",
    "            subset='training',\n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        validation_generator = datagen.flow_from_directory(\n",
    "            data_dir,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical',\n",
    "            subset='validation',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.class_names = list(train_generator.class_indices.keys())\n",
    "        \n",
    "        return train_generator, validation_generator\n",
    "\n",
    "    def train(self, data_dir=\"input/AI-face-detection-Dataset\", epochs=50):\n",
    "        train_generator, validation_generator = self.prepare_data(data_dir)\n",
    "        \n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        history = self.model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        if self.class_names is None:\n",
    "            raise ValueError(\"Model must be trained before prediction\")\n",
    "        \n",
    "        img = load_img(image_path, target_size=(self.img_height, self.img_width))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "        \n",
    "        prediction = self.model.predict(img_array)\n",
    "        predicted_class_index = np.argmax(prediction)\n",
    "        predicted_class = self.class_names[predicted_class_index]\n",
    "        confidence = prediction[0][predicted_class_index] * 100\n",
    "        \n",
    "        return f\"{predicted_class} (Confidence: {confidence:.2f}%)\"\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == '__main__':\n",
    "    classifier = AIImageClassifier(img_height=150, img_width=150)\n",
    "    classifier.train(\"input/AI-face-detection-Dataset\")\n",
    "    \n",
    "    # Example: Predict all images in input/\n",
    "    for filename in os.listdir(\"input\"):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            img_path = os.path.join(\"input\", filename)\n",
    "            result = classifier.predict(img_path)\n",
    "            print(f\"{filename}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1546c4a2-4f38-416e-8eb7-732df72fe1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "AI Generated (Confidence: 94.52%)\n"
     ]
    }
   ],
   "source": [
    "    # Predict single image\n",
    "    result = classifier.predict(r\"C:\\\\Users\\\\soumy\\\\Downloads\\\\vecteezy_ai-generated-indian-female-student_39334804.jpg\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c66b1d0-67b4-4115-90b8-90a82df8d8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "AI Generated (Confidence: 85.57%)\n"
     ]
    }
   ],
   "source": [
    "    # Predict single image\n",
    "    result = classifier.predict(r\"C:\\\\Users\\\\soumy\\\\Downloads\\\\ai-generated-image.jpg\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e123c3a6-445e-4c21-936b-72931e678d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "AI Generated (Confidence: 53.08%)\n"
     ]
    }
   ],
   "source": [
    "    # Predict single image\n",
    "    result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\Armaan_Malik_2016.jpg\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cd9659e-40ac-4855-9bd8-b770da3a8804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Real Image (Confidence: 97.87%)\n"
     ]
    }
   ],
   "source": [
    "# Predict single image\n",
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\WhatsApp Image 2025-01-09 at 11.01.21.jpeg\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41cd6fe-7b85-4ea4-a50c-46bfa4d792a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Real Image (Confidence: 88.68%)\n"
     ]
    }
   ],
   "source": [
    "# Example prediction\n",
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\WhatsApp Image 2025-01-09 at 11.01.22.jpeg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3124458f-261d-401c-a6a8-224f40b1528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "Real Image (Confidence: 99.94%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\ai-real\\AI-face-detection-Dataset\\Real Image\\non-child-978.png\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe9ef33c-6520-4785-acbd-b898666bfb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "Real Image (Confidence: 98.94%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\images.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2746847-0241-4600-a7ec-2f32653d7bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
      "AI Generated (Confidence: 93.46%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\no-filters-closeup-portrait-young-260nw-2103259805.webp\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "809304ef-50a5-4129-80ac-55320dd26d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "Real Image (Confidence: 82.94%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\OneDrive\\Pictures\\Camera Roll\\WIN_20250124_22_29_33_Pro.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "466524f4-212b-45f8-95e5-410724dbbfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "AI Generated (Confidence: 64.81%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\premium_photo-1661585987573-c5873c7e258e.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a40769b4-404a-433a-83a1-4f5bf9d48e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "Real Image (Confidence: 99.45%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\pexels-photo-2379005.jpeg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f99c3778-5aba-4af2-b1d7-ece2ca919e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "Real Image (Confidence: 69.71%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\v3_0924096 ai generated.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "258e4d1f-5859-4069-9ddf-f190d09a98fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "AI Generated (Confidence: 92.72%)\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(r\"C:\\Users\\soumy\\Downloads\\v3_0344789 ai generated.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b92473-9c88-4e89-9ffb-7cb315384861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
